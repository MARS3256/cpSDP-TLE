{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42c000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions saved to output/predictions/same-project/ant16_to_ant17.csv\n",
      "✓ Metrics saved to output/predictions/same-project/ant16_to_ant17_result.csv\n",
      "✓ Predictions shape: (745, 5)\n",
      "\n",
      "First 5 predictions:\n",
      "                                                Name    SVM   KNN    RF  Bug\n",
      "0  org.apache.tools.ant.taskdefs.rmic.RmicAdapter...  16.22  40.0  47.0    0\n",
      "1  org.apache.tools.ant.taskdefs.optional.perforc...   8.65   0.0   5.0    0\n",
      "2  org.apache.tools.ant.taskdefs.optional.junit.O...  14.13  20.0   0.0    0\n",
      "3  org.apache.tools.ant.taskdefs.optional.perforc...  13.79  40.0  13.0    0\n",
      "4              org.apache.tools.ant.taskdefs.WaitFor  12.69   0.0   4.0    1\n",
      "\n",
      "Metrics:\n",
      "Method  Accuracy  Precision  Recall  F1-Score  AUC\n",
      "   SVM      0.80       0.58    0.45      0.51 0.80\n",
      "   KNN      0.79       0.52    0.49      0.50 0.76\n",
      "    RF      0.79       0.53    0.47      0.50 0.80\n",
      "\n",
      "Actual bug distribution: {0: 579, 1: 166}\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Function to train and predict with SVM, KNN, RF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import os\n",
    "\n",
    "def train_and_predict(train_path, test_path, output_filename, metrics_filename, output_folder='output/predictions/same-project'):\n",
    "    \"\"\"\n",
    "    Train SVM, KNN, and RF models on training data and predict on test data.\n",
    "    \n",
    "    Args:\n",
    "        train_path: Path to training CSV file\n",
    "        test_path: Path to test CSV file\n",
    "        output_filename: Name for output predictions CSV file\n",
    "        metrics_filename: Name for output metrics CSV file\n",
    "        output_folder: Folder path for output files (default: 'output/predictions/same-project')\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (predictions DataFrame, metrics DataFrame)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load datasets\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        # Store names and actual bug values for output\n",
    "        test_names = test_df['name'].copy()\n",
    "        test_bugs = (test_df['bug'] > 0).astype(int)  # Binary: 1 if bug>0, else 0\n",
    "        \n",
    "        # Prepare training data\n",
    "        # X_train: All columns except 'name' (identifier) and 'bug' (target variable)\n",
    "        X_train = train_df.drop(['name', 'bug'], axis=1)\n",
    "        # y_train: Binary classification - 1 if bug count > 0, else 0\n",
    "        y_train = (train_df['bug'] > 0).astype(int)\n",
    "        \n",
    "        # Prepare test data\n",
    "        # X_test: Same features as X_train (drop 'name' and 'bug')\n",
    "        X_test = test_df.drop(['name', 'bug'], axis=1)\n",
    "        \n",
    "        # Scale features for better model performance\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train and predict with SVM\n",
    "        svm_model = SVC(probability=True, random_state=42)\n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "        svm_proba = svm_model.predict_proba(X_test_scaled)[:, 1] * 100\n",
    "        svm_pred = svm_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Train and predict with KNN\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn_model.fit(X_train_scaled, y_train)\n",
    "        knn_proba = knn_model.predict_proba(X_test_scaled)[:, 1] * 100\n",
    "        knn_pred = knn_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Train and predict with Random Forest\n",
    "        rf_model = RandomForestClassifier(random_state=42)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        rf_proba = rf_model.predict_proba(X_test_scaled)[:, 1] * 100\n",
    "        rf_pred = rf_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Create output DataFrame with predictions and actual bug values\n",
    "        output_df = pd.DataFrame({\n",
    "            'Name': test_names,\n",
    "            'SVM': svm_proba,\n",
    "            'KNN': knn_proba,\n",
    "            'RF': rf_proba,\n",
    "            'Bug': test_bugs\n",
    "        })\n",
    "        \n",
    "        # Format to 2 decimal places\n",
    "        output_df['SVM'] = output_df['SVM'].round(2)\n",
    "        output_df['KNN'] = output_df['KNN'].round(2)\n",
    "        output_df['RF'] = output_df['RF'].round(2)\n",
    "        \n",
    "        # Calculate metrics for each model\n",
    "        metrics_data = []\n",
    "        \n",
    "        for model_name, y_pred, y_proba_pct in [\n",
    "            ('SVM', svm_pred, svm_proba),\n",
    "            ('KNN', knn_pred, knn_proba),\n",
    "            ('RF', rf_pred, rf_proba)\n",
    "        ]:\n",
    "            y_proba = y_proba_pct / 100  # Convert back to 0-1 range for metrics\n",
    "            \n",
    "            metrics_data.append({\n",
    "                'Method': model_name,\n",
    "                'Accuracy': accuracy_score(test_bugs, y_pred),\n",
    "                'Precision': precision_score(test_bugs, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(test_bugs, y_pred, zero_division=0),\n",
    "                'F1-Score': f1_score(test_bugs, y_pred, zero_division=0),\n",
    "                'AUC': roc_auc_score(test_bugs, y_proba)\n",
    "            })\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        \n",
    "        # Format metrics to 2 decimal places\n",
    "        for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']:\n",
    "            metrics_df[col] = metrics_df[col].round(2)\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Save predictions to CSV\n",
    "        output_path = f'{output_folder}/{output_filename}'\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Save metrics to CSV\n",
    "        metrics_path = f'{output_folder}/{metrics_filename}'\n",
    "        metrics_df.to_csv(metrics_path, index=False)\n",
    "        \n",
    "        print(f\"✓ Predictions saved to {output_path}\")\n",
    "        print(f\"✓ Metrics saved to {metrics_path}\")\n",
    "        print(f\"✓ Predictions shape: {output_df.shape}\")\n",
    "        print(f\"\\nFirst 5 predictions:\")\n",
    "        print(output_df.head())\n",
    "        print(f\"\\nMetrics:\")\n",
    "        print(metrics_df.to_string(index=False))\n",
    "        print(f\"\\nActual bug distribution: {test_bugs.value_counts().to_dict()}\")\n",
    "        \n",
    "        return output_df, metrics_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Execute: Train on ant-1.6, predict on ant-1.7\n",
    "result1_pred, result1_metrics = train_and_predict(\n",
    "    'datasets/same-project/train/ant-1.6.csv',\n",
    "    'datasets/same-project/test/ant-1.7.csv',\n",
    "    'ant16_to_ant17.csv',\n",
    "    'ant16_to_ant17_result.csv',\n",
    "    'output/predictions/same-project'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8315e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions saved to output/predictions/same-project/ant17_to_ivy11.csv\n",
      "✓ Metrics saved to output/predictions/same-project/ant17_to_ivy11_result.csv\n",
      "✓ Predictions shape: (241, 5)\n",
      "\n",
      "First 5 predictions:\n",
      "                                                Name    SVM   KNN    RF  Bug\n",
      "0  fr.jayasoft.ivy.repository.vfs.IvyWebdavFileSy...  14.87  40.0  16.0    0\n",
      "1            fr.jayasoft.ivy.util.EncrytedProperties  12.70   0.0   6.0    0\n",
      "2     fr.jayasoft.ivy.xml.XmlModuleDescriptorUpdater  18.29  20.0  34.0    1\n",
      "3            fr.jayasoft.ivy.resolver.IvyRepResolver  33.08  40.0  52.0    0\n",
      "4  fr.jayasoft.ivy.event.resolve.StartResolveDepe...  13.40   0.0   7.0    0\n",
      "\n",
      "Metrics:\n",
      "Method  Accuracy  Precision  Recall  F1-Score  AUC\n",
      "   SVM      0.90       0.23    0.19      0.21 0.69\n",
      "   KNN      0.85       0.12    0.19      0.14 0.63\n",
      "    RF      0.86       0.19    0.31      0.23 0.71\n",
      "\n",
      "Actual bug distribution: {0: 225, 1: 16}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Train on ant-1.7, predict on ivy-1.1\n",
    "result2_pred, result2_metrics = train_and_predict(\n",
    "    'datasets/same-project/train/ant-1.7.csv',\n",
    "    'datasets/same-project/test/ivy-1.1.csv',\n",
    "    'ant17_to_ivy11.csv',\n",
    "    'ant17_to_ivy11_result.csv',\n",
    "    'output/predictions/cross-project'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions saved to output/predictions/same-project/camel16_to_synapse12.csv\n",
      "✓ Metrics saved to output/predictions/same-project/camel16_to_synapse12_result.csv\n",
      "✓ Predictions shape: (256, 5)\n",
      "\n",
      "First 5 predictions:\n",
      "                                                Name    SVM   KNN     RF  Bug\n",
      "0   org.apache.synapse.endpoints.LoadbalanceEndpoint  37.92  60.0  53.00    1\n",
      "1  org.apache.synapse.util.concurrent.SynapseThre...  17.28   0.0  27.00    0\n",
      "2      org.apache.synapse.mediators.AbstractMediator  82.74  80.0  72.00    1\n",
      "3  org.apache.synapse.config.xml.AnonymousListMed...  19.09  60.0  16.67    0\n",
      "4  org.apache.synapse.endpoints.algorithms.Loadba...  17.24   0.0  13.00    1\n",
      "\n",
      "Metrics:\n",
      "Method  Accuracy  Precision  Recall  F1-Score  AUC\n",
      "   SVM      0.68       0.62    0.09      0.16 0.70\n",
      "   KNN      0.66       0.49    0.34      0.40 0.61\n",
      "    RF      0.70       0.63    0.28      0.39 0.66\n",
      "\n",
      "Actual bug distribution: {0: 170, 1: 86}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Train on camel-1.6, predict on synapse-1.2\n",
    "result3_pred, result3_metrics = train_and_predict(\n",
    "    'datasets/integration-messaging/train/camel-1.6.csv',\n",
    "    'datasets/integration-messaging/test/synapse-1.2.csv',\n",
    "    'camel16_to_synapse12.csv',\n",
    "    'camel16_to_synapse12_result.csv',\n",
    "    'output/predictions/cross-project'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
